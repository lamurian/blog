---
title: "Generalized Linear Model"
author: Aly Lamuri
output:
  xaringan::moon_reader:
    css: ["shinobi", "ninjutsu"]
    seal: false
    self_contained: false
    nature:
      ratio: "16:9"
      countIncrementalSlides: false
      highlightLines: true
---

count: false
class: bg-main1 split-70 hide-slide-number

```{r init, echo=FALSE}
pkgs <- c("magrittr", "kableExtra", "ggplot2", "ggpubr")
pkgs.load <- sapply(pkgs, library, character.only=TRUE)
knitr::opts_chunk$set(echo=T, eval=T, message=F, warning=F, error=F,
	fig.width=10, fig.height=6, out.width="90%", dev="png", dpi=300
)
options(digits=2)
```

.column[.vmiddle.right.content[
.font3[.amber[Generalized] Linear Model]
]]

.column.bg-main4[.vmiddle.content[
.amber[Aly Lamuri]  
Indonesia Medical Education and Research Institute
]]

---

name: overview
layout: true
class: bg-main4 split-30 hide-slide-number

.column[.vmiddle.right.content[
.font3.amber[Overview]
]]

---

count: false
template: overview

.column.bg-main1[.vmiddle.content[
- .amber[Concept]
- Logistic regression
- Poisson regression
]]

---

layout: true
class: bg-main3

# Concept

.font2[
\begin{align}
\hat{y} &= \beta_0 + \beta_1 x_1 \\
y & \sim g(\hat{y}) + \epsilon
\end{align}
]

---

.font2[
- Generalized form of linearity
- Similarity to the core concept of LM
- Model other families of error distribution
- Link function $g$
]

???

- LM is a GLM with Gaussian (normal) error distribution
- Other families supported in `R`: Binomial, Gamma, inverse Gaussian, Poisson,
  Quasi, Quasibinomial, Quasipoisson

---

count: false

## Link function

.font2[
- $E(\hat{y}) \sim N(\mu, \sigma)$
- Does not need to directly transform the actual $y$
- Important bit: identity, binomial, poisson link function
]

???

- Recall: in `lm`, we are interested to obtain $E(\hat{y}) = \beta_0 + \beta_1
  x_1$
- When the residual does not follow a normal distribution, so does the
  $E(\hat{y})$
- A link function provides a general conversion between $\hat{y}$ and the
  non-normally distributed $y$
- This way, we don't have to transform the individual value of $y_i$

---

count: false

.font2[
- Recall: $\hat{y} \sim \epsilon$
- $\epsilon \sim N(\mu, \sigma) \to MLE = OLS$
- In GLM: $\epsilon$ may not follow a normal distribution
- The dependent variable $y$ follows an .amber[exponential family] distributions
]

???

- $\hat{y}$ is the expected value, as linearly defined by $\beta_0 + \beta_1 x_1$
- The predicted value $\hat{y}$ will have a probability distribution as defined
  by $\epsilon$
- When $\epsilon$ follows a normal distribution, $MLE = OLS$ in estimating the
  value of $\beta$
- Since GLM does not assume normality of the $\epsilon$, we will have different
  $\beta$ estimation using $MLE$ and $OLS$ $\to$ ask why?
- Though, in GLM, $IWLS = MLE$ (Iteratively Re-weighted Least Square)

---

layout: false
class: bg-main3

# Distribution family and link function

<br>

```{r link.fun, echo=FALSE}

tbl <- data.frame(list(
	"Distribution" = c("Gaussian", "Binomial", "Poisson", "Gamma", "Inverse Gaussian"),
	"Link Function" = c("Identity, log, inverse", "Logit, probit", "Log, inverse square root", "Inverse, identity, log", "1/square root, inverse, log")
), check.names=FALSE)

kable(tbl) %>% kable_material_dark()

```

---

layout: true
class: bg-main3

# Exponential family distributions

---

.font2[
- $P(x | \eta) = h(x)\ exp \big\{ \eta^T T(x) - A(\eta) \big\}$
- $\eta$: Canonical parameter
- $T(X)$: Sufficient statistic
- $A(\eta)$: Cumulant function
]

???

- $T$ and $h$ are functions
- Differentiate from exponential distribution
- In exponential distribution, the probability $P(x|\lambda) = \lambda e^{- \lambda x}$

---

count: false

.font2[
- The exponential .amber[family] describes a group of probability distributions
- It includes:
  - Gaussian (normal)
  - Binomial
  - Poisson
  - Gamma
  - Inverse gaussian
]

--

.font2[Sounds .amber[familiar]?]

???

- GLM revolves around the exponential family distribution
- It assumes that the error term $\epsilon$ may follow a non-normal distribution
- The probability equation on the exponential family can derive into a plethora
  of distribution function, as described above

--

.font2[
Exponential family $\to$ .amber[Convert] probability functions into
its exponential form
]

---

layout: true
class: bg-main3

# Example, please?

.font2[
$$P(x | \eta) = h(x)\ exp \big\{ \eta^T T(x) - A(\eta) \big\}$$
]

---

.font2[
Consider the following probability distributions:

- Bernoulli
- Poisson
- Normal
]

---

## Bernoulli distribution

\begin{align}
P(x | p) &= p^x (1-p)^{1-x} \tag{P.D.F} \\
&= exp \left\{ \log \left( \frac{p}{1-p} \right) x + \log(1-p) \right\} \\
\\
\eta &= \frac{p}{1-p} \\
T(x) &= x \\
A(\eta) &= -\log (1-p) = \log(1+e^{\eta}) \\
h(x) &= 1
\end{align}

---

count: false

## Poisson distribution

\begin{align}
P(x | \lambda) &= \frac{\lambda^x e^{-\lambda}}{x!} \\
&= \frac{1}{x!} exp \big\{ x\ \log \lambda - \lambda \big\} \\
\\
\eta &= \log \lambda \\
T(x) &= x \\
A(\eta) &= \lambda = e^{\eta} \\
h(x) &= \frac{1}{x!}
\end{align}

---

count: false

## Gaussian distribution

\begin{align}
P(x | \mu, \sigma) = \frac{1}{\sqrt{2 \pi \sigma^2}} e^{- \frac{(x - \mu)^2}{2 \sigma^2}} &= \frac{1}{\sqrt{2 \pi \sigma^2}} exp \left\{ \frac{\mu}{\sigma^2}x - \frac{1}{2 \sigma^2}x^2 - \frac{1}{2 \sigma^2} \mu^2 - \log \sigma \right\} \\
\\
\eta &= \left[ \begin{matrix} \mu / \sigma^2 \\ -1/2 \sigma^2 \end{matrix} \right] \\
T(x) &= \left[ \begin{matrix} x \\ x^2 \end{matrix} \right] \\
A(\eta) &= \frac{\mu^2}{2 \sigma^2} + \log \sigma = - \frac{\eta_1^2}{4 \eta_2} - \frac{1}{2} \log (-2 \eta_2) \\
h(x) &= \frac{1}{\sqrt{2\pi}}
\end{align}

---

layout: false
class: bg-main3

# Excerpt

.font2[
- We can .amber[generalize] any member of exponential family
- This is an important concept in the .amber[Generalized] Linear Model
- Error term $\epsilon \sim$ exponential family distributions
- Recall: the link function
]

---

layout: false
class: bg-main3

# Finding the .amber[p]-value

.font2[
- The $t$ statisctis to measure significance
- We set our hypotheses based on each observable variables
- The $t$ statistics is derived from the estimate $\beta_i$
]

---

count: false
template: overview

.column.bg-main1[.vmiddle.content[
- Concept
- .amber[Logistic regression]
- Poisson regression
]]

---

layout: true
class: bg-main3

# .amber[Logistic] regression

---

.font2[
- Conceptual remark: what do you use a Binomial distribution for?
- Also termed .amber[logit-linear] regression
- Using the logit link function
]

---

count: false

.font2[
- In binomial distribution: 2 possible outcomes
- $X \sim B(n, p)$
- The probability $p \in [0, 1]$
- The link function .amber[generalizes] $p \to [-\infty, \infty]$
]

--

.font2[
\begin{align}
E(\hat{y}) &= ln \left( OR \right) \\
OR &= \frac{p}{1-p}
\end{align}
]

???

- OR is the odds ratio
- Another link function variants of binomial family are probit and cauchit

---

layout: false
class: bg-main3

# Interpretation

.font2[
- Understanding the $\log$ of an outcome is difficult!
- We impute the estimate $\beta_i$ into an exponential function $exp$
- By exponentiating, we will get the odds ratio (.amber[OR])
- It simply describe what the .amber[odds] of a certain variable in determining the .amber[outcome]
]

???

- This model helps us classifying a particular outcome to happen
- ...when we know the determinant (independent variables)

---

layout: true
class: bg-main3

# Example, please?

---

.font2[
- Here, we will (again) use the `iris` dataset
- However, a logistic regression model only accepts .amber[two] outcomes
- Thus, we make a subset to only include .amber[two] species to make a classification model
]

---

count: false

```{r logreg1}
tbl <- subset(iris, subset={iris$Species!="setosa"})
tbl$Species %<>% factor()
str(tbl)
```

---

count: false

```{r logreg2}
logreg <- glm(
	Species ~ Sepal.Length + Petal.Length,
	data=tbl, family=binomial # By default, it uses logit link
) %T>% print()
```

---

count: false

```{r logreg3}
broom::tidy(logreg) %>% kable() %>% kable_material_dark()
```

---

count: false

```{r logreg4}
coef(logreg) %>% exp() # Exponentiated estimate
confint(logreg) %>% exp() # Exponentiated confidence interval
rsq::rsq(logreg) # The R-squared
```

???

Interpretation:
- The exponentiated estimates are the odds ratio
- Suppose you have a variable of interest
- When the $OR=1$, the IV does not contribute to classifying the DV
- Read it out loud: the odds of having DV when having the IV is 1x higher than
  not having it at all
- It's important to check whether the confidence interval reached the value of 1

---

count: false

```{r logreg4.1}
lmtest::bptest(logreg)
lmtest::hmctest(logreg)
```

---

count: false

```{r logreg5, echo=F}
par(mfrow=c(2, 2))
autoplot(logreg) + theme_minimal()
```

---

count: false
template: overview

.column.bg-main1[.vmiddle.content[
- Concept
- Logistic regression
- .amber[Poisson regression]
]]

---

layout: true
class: bg-main3

# .amber[Poisson] regression

---

.font2[
- Conceptual remark: what do you use a Poisson distribution for?
- Also termed .amber[log-linear] regression
- Using a log link function
]

---

count: false

.font2[
- In Poisson distribution: probability of a rate $\lambda$
- $X \sim P(\lambda)$
- The rate $\lambda \in \mathbb{N}$
- The link function .amber[generalizes] $\lambda \to [-\infty, \infty]$
]

--

.font2[
\begin{align}
E(\hat{y}) &= ln(\lambda)
\end{align}
]

???

- It models a count data as its DV

---

layout: false
class: bg-main3

# Interpretation

.font2[
- As in logistic regression, understanding the $\log$ is not easy
- So we impute the estimate $\beta_i$ into an exponential function $\exp$
- By exponentiating, we will get the incidence rate ratio (.amber[IRR])
- It describes what the rate of a DV to happen given the IV
]

???

- The estimate reflect the IRR
- IRR: Incidence Rate Ratio

---

layout: true
class: bg-main3

# Example, please?

---

.font2[
- This example will use `Seatbelts` dataset in `R`
- We will use the variable `DriversKilled` as the DV
- .red[Disclaimer:] Poisson regression is not a suitable model for a
  time-series data
]

---

count: false

```{r poisreg1}
str(Seatbelts)
head(Seatbelts)
```

???

- `DriversKilled` is the number of casualties within a particular time frame
- `law` is whether the compulsory seatbelts utilization has been enforced
- `front` and `back`: Front and back-seat passengers with casualties
- `kms`: Distance in km

---

count: false

```{r poisreg2}
poisreg <- glm(
	DriversKilled ~ kms + law + PetrolPrice,
	data=Seatbelts, family=poisson
) %T>% print()
```

---

count: false

```{r poisreg3}
broom::tidy(poisreg) %>% kable() %>% kable_material_dark()
```

---

count: false

```{r poisreg4}
coef(poisreg) %>% exp()
confint(poisreg) %>% exp()
rsq::rsq(poisreg)
```

---

count: false

```{r poisreg4.1}
lmtest::bptest(poisreg)
lmtest::hmctest(poisreg)
```

---

count: false

```{r poisreg5, echo=F}
autoplot(poisreg) + theme_minimal()
```

---

count: false
layout: false
class: bg-main1 font5 hide-slide-number middle center

.amber[Query?]
